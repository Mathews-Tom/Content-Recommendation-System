{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "\n",
    "To run this notebook you just need to have [pipenv](https://github.com/pypa/pipenv) installed. Then run these 3 commands:\n",
    "\n",
    "1. Install the dependencies with: `pipenv install`\n",
    "2. Launch the virtual env: `pipenv shell`\n",
    "3. Start jupyter and open the notebook: `jupyter-lab`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 689 ms (started: 2022-11-12 01:25:23 +05:30)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autotime\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import requests\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel \n",
    "\n",
    "from surprise import NormalPredictor, SVD, KNNBasic, NMF\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import cross_validate, KFold\n",
    "\n",
    "from tempfile import NamedTemporaryFile\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Recommender systems goal is to push relevant items to a given user. Understanding and modelling the user's preferences is required to reach this goal. In this project we will learn how to model the user's preferences with the [Surprise library](http://surpriselib.com/) to build different recommender systems. The first one will be a pure collaborative filtering approach, and the second one will rely on item attributes in a content-based way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Downloading and Loading Data\n",
    "\n",
    "We use here the [MovieLens dataset](https://grouplens.org/datasets/movielens/). It contains 25 millions of users ratings. the data are in the `./data/raw` folder. We could load directly the .csv file with a built-in Surprise function, but it's more convenient to load it through a Pandas dataframe for later flexibility purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 262M/262M [00:28<00:00, 9.05MiB/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:02<00:00,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 32.8 s (started: 2022-11-12 01:25:24 +05:30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download and extract the dataset\n",
    "\n",
    "zip_file_name = \"ml-25m.zip\"\n",
    "zip_url = \"https://files.grouplens.org/datasets/movielens/ml-25m.zip\"\n",
    "\n",
    "\n",
    "response = requests.get(zip_url, stream=True)\n",
    "total_size_in_bytes= int(response.headers.get('content-length', 0))\n",
    "block_size = 1024 #1 Kibibyte\n",
    "progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True)\n",
    "\n",
    "with open(zip_file_name, 'wb') as file:\n",
    "    for data in response.iter_content(block_size):\n",
    "        progress_bar.update(len(data))\n",
    "        file.write(data)\n",
    "    progress_bar.close()\n",
    "if total_size_in_bytes != 0 and progress_bar.n != total_size_in_bytes:\n",
    "    print(\"ERROR, something went wrong\")\n",
    "    \n",
    "with ZipFile(zip_file_name, \"r\") as zip_ref:\n",
    "    for file in tqdm(iterable=zip_ref.namelist(), total=len(zip_ref.namelist())):\n",
    "        zip_ref.extract(member=file)\n",
    "        \n",
    "os.remove(zip_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 223 µs (started: 2022-11-12 01:25:57 +05:30)\n"
     ]
    }
   ],
   "source": [
    "RATINGS_DATA_FILE = f\"{zip_file_name[:-4]}/ratings.csv\"\n",
    "MOVIES_DATA_FILE = f\"{zip_file_name[:-4]}/movies.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.78 s (started: 2022-11-12 01:25:57 +05:30)\n"
     ]
    }
   ],
   "source": [
    "# Load the raw csv into a data_frame\n",
    "df_ratings = pd.read_csv(RATINGS_DATA_FILE)\n",
    "\n",
    "# Drop the timestamp column since we dont need it now\n",
    "df_ratings = df_ratings.drop(columns=\"timestamp\")\n",
    "\n",
    "# Movies dataframe\n",
    "df_movies = pd.read_csv(MOVIES_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000095"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31.8 ms (started: 2022-11-12 01:26:00 +05:30)\n"
     ]
    }
   ],
   "source": [
    "# check we have 25M users' ratings\n",
    "df_ratings.userId.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 617 ms (started: 2022-11-12 01:26:00 +05:30)\n"
     ]
    }
   ],
   "source": [
    "def get_subset(df, number):\n",
    "    \"\"\"\n",
    "    Get a subset of a large dataset for debug purpose.\n",
    "    \"\"\"\n",
    "    rids = np.arange(df.shape[0])\n",
    "    np.random.shuffle(rids)\n",
    "    df_subset = df.iloc[rids[:number], :].copy()\n",
    "    return df_subset\n",
    "\n",
    "df_ratings_1k = get_subset(df_ratings, 1000)\n",
    "df_movies_100 = get_subset(df_movies, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 841 µs (started: 2022-11-12 01:26:01 +05:30)\n"
     ]
    }
   ],
   "source": [
    "# Surprise reader\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "\n",
    "# Finally load all ratings\n",
    "ratings = Dataset.load_from_df(df_ratings_1k, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19890974</th>\n",
       "      <td>129330</td>\n",
       "      <td>8798</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513320</th>\n",
       "      <td>10115</td>\n",
       "      <td>3552</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9285614</th>\n",
       "      <td>60497</td>\n",
       "      <td>1291</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7382990</th>\n",
       "      <td>47868</td>\n",
       "      <td>1265</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7136723</th>\n",
       "      <td>46264</td>\n",
       "      <td>1320</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId  movieId  rating\n",
       "19890974  129330     8798     3.5\n",
       "1513320    10115     3552     3.0\n",
       "9285614    60497     1291     2.0\n",
       "7382990    47868     1265     3.5\n",
       "7136723    46264     1320     3.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.31 ms (started: 2022-11-12 01:26:01 +05:30)\n"
     ]
    }
   ],
   "source": [
    "df_ratings_1k.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Collaborative Filtering\n",
    "\n",
    "We can test first any of the [Surprise algorithms](https://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 491 µs (started: 2022-11-12 01:26:01 +05:30)\n"
     ]
    }
   ],
   "source": [
    "# Define a cross-validation iterator\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "algos = [SVD(), NMF(), KNNBasic()]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 25.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.1176\n",
      "RMSE: 1.1298\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.1201\n",
      "RMSE: 1.1436\n",
      "RMSE: 1.1449\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.1435\n",
      "RMSE: 1.1038\n",
      "RMSE: 1.1083\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.1081\n",
      "time: 121 ms (started: 2022-11-12 01:26:01 +05:30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_rmse(algo, testset):\n",
    "    predictions = algo.test(testset)\n",
    "    accuracy.rmse(predictions, verbose=True)\n",
    "        \n",
    "for trainset, testset in tqdm(kf.split(ratings)): \n",
    "    \"\"\"\n",
    "    Get an evaluation with cross-validation for different algorithms.\n",
    "    \"\"\"  \n",
    "    for algo in algos:\n",
    "        algo.fit(trainset)\n",
    "        get_rmse(algo, testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Content-based Filtering\n",
    "\n",
    "Here we will rely directly on items attributes. First we have to describe a user profile with an attributes vector. Then we will use these vectors to generate recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 276 µs (started: 2022-11-12 01:26:01 +05:30)\n"
     ]
    }
   ],
   "source": [
    "# Computing similarities requires too much ressources on the whole dataset, so we take the subset with 100 items\n",
    "\n",
    "df_movies_100 = df_movies_100.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.14 ms (started: 2022-11-12 01:26:01 +05:30)\n"
     ]
    }
   ],
   "source": [
    "# Compute a TFIDF on the titles of the movies\n",
    "\n",
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), min_df=0, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(df_movies_100['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.08 ms (started: 2022-11-12 01:26:01 +05:30)\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarities: this takes a lot of time on the real dataset\n",
    "\n",
    "cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 951 ms (started: 2022-11-12 01:26:01 +05:30)\n"
     ]
    }
   ],
   "source": [
    "# We generate in 'results' the most similar movies for each movie: we put a pair (score, movie_id)\n",
    "\n",
    "results = {}\n",
    "for idx, row in df_movies_100.iterrows():\n",
    "    similar_indices = cosine_similarities[idx].argsort()[:-100:-1] \n",
    "    similar_items = [(cosine_similarities[idx][i], df_movies_100['movieId'].loc[[i]].tolist()[0]) for i in similar_indices] \n",
    "    results[idx] = similar_items[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 230 µs (started: 2022-11-12 01:26:02 +05:30)\n"
     ]
    }
   ],
   "source": [
    "# Transform a 'movieId' into its corresponding movie title\n",
    "\n",
    "def item(id):  \n",
    "    return df_movies_100.loc[df_movies_100['movieId'] == id]['title'].tolist()[0].split(' - ')[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 198 µs (started: 2022-11-12 01:26:02 +05:30)\n"
     ]
    }
   ],
   "source": [
    "# Transform a 'movieId' into the index id\n",
    "\n",
    "def get_idx(id):\n",
    "    return df_movies_100[df_movies_100['movieId'] == id].index.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 273 µs (started: 2022-11-12 01:26:02 +05:30)\n"
     ]
    }
   ],
   "source": [
    "# Finally we put everything together here:\n",
    "\n",
    "def recommend(item_id, num):\n",
    "    print(\"Recommending \" + str(num) + \" products similar to \" + item(item_id) + \"...\")   \n",
    "    print(\"-------\")    \n",
    "    recs = results[get_idx(item_id)][:num]   \n",
    "    for rec in recs: \n",
    "        print(\"\\tRecommended: \" + item(rec[1]) + \" (score:\" +      str(rec[0]) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77332</td>\n",
       "      <td>Don's Plum (2001)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>164111</td>\n",
       "      <td>From the Land of the Moon (2016)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99222</td>\n",
       "      <td>Silent Night (2012)</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>190817</td>\n",
       "      <td>The Miles Davis Story (2001)</td>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>164685</td>\n",
       "      <td>Sometimes Aunt Martha Does Dreadful Things (1971)</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                                              title         genres\n",
       "0    77332                                  Don's Plum (2001)          Drama\n",
       "1   164111                   From the Land of the Moon (2016)  Drama|Romance\n",
       "2    99222                                Silent Night (2012)         Horror\n",
       "3   190817                       The Miles Davis Story (2001)    Documentary\n",
       "4   164685  Sometimes Aunt Martha Does Dreadful Things (1971)         Horror"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.15 ms (started: 2022-11-12 01:26:02 +05:30)\n"
     ]
    }
   ],
   "source": [
    "df_movies_100.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommending 10 products similar to The Miles Davis Story (2001)...\n",
      "-------\n",
      "\tRecommended: 61* (2001) (score:0.12749864647542272)\n",
      "\tRecommended: Don's Plum (2001) (score:0.08690617461050223)\n",
      "\tRecommended: Legally Blonde (2001) (score:0.08690617461050223)\n",
      "\tRecommended: Human Nature (2001) (score:0.08690617461050223)\n",
      "\tRecommended: The Misfit Brigade (1987) (score:0.0)\n",
      "\tRecommended: Goods: Live Hard, Sell Hard, The (2009) (score:0.0)\n",
      "\tRecommended: Scott Walker: 30 Century Man (2006) (score:0.0)\n",
      "\tRecommended: Battle in Seattle (2007) (score:0.0)\n",
      "\tRecommended: Ukonvaaja (2016) (score:0.0)\n",
      "\tRecommended: Rurouni Kenshin (Rurôni Kenshin: Meiji kenkaku roman tan) (2012) (score:0.0)\n",
      "time: 2.4 ms (started: 2022-11-12 01:26:02 +05:30)\n"
     ]
    }
   ],
   "source": [
    "random_item_id = random.choice(df_movies_100[\"movieId\"].tolist())\n",
    "recommend(item_id=random_item_id, num=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
